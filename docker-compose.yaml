services:
  # ===========================================
  # Ollama - LLM Locale
  # ===========================================
  ollama:
    image: ollama/ollama:latest
    container_name: smartrecruit-ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    networks:
      - smartrecruit-net
    restart: unless-stopped
    # Per GPU NVIDIA (opzionale, decommentare se hai GPU):
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # ===========================================
  # n8n - Workflow Automation
  # ===========================================
  n8n:
    image: n8nio/n8n:latest
    container_name: smartrecruit-n8n
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_USER:-admin}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD:-changeme123!}
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=${N8N_PROTOCOL:-http}
      - N8N_SECURE_COOKIE=false
      - WEBHOOK_URL=${WEBHOOK_URL:-http://localhost:5678}
      - GENERIC_TIMEZONE=${TIMEZONE:-Europe/Rome}
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY:-generate_with_openssl}

      # Ollama Configuration
      - OLLAMA_HOST=http://ollama:11434

      # GitHub Token (set via .env)
      - GITHUB_TOKEN=${GITHUB_TOKEN}

      # Performance
      - N8N_PAYLOAD_SIZE_MAX=16
      - EXECUTIONS_DATA_PRUNE=true
      - EXECUTIONS_DATA_MAX_AGE=168

      # Execution settings
      - EXECUTIONS_PROCESS=main
      - EXECUTIONS_DATA_SAVE_ON_ERROR=all
      - EXECUTIONS_DATA_SAVE_ON_SUCCESS=all
      - EXECUTIONS_DATA_SAVE_MANUAL_EXECUTIONS=true
    volumes:
      - n8n_data:/home/node/.n8n
      - ./workflows:/backup
    ports:
      - "5678:5678"
    depends_on:
      - ollama
    networks:
      - smartrecruit-net
    restart: unless-stopped

  # ===========================================
  # Ollama Web UI (opzionale - interfaccia web per Ollama)
  # ===========================================
  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: smartrecruit-ollama-webui
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      - ollama_webui_data:/app/backend/data
    ports:
      - "8080:8080"
    depends_on:
      - ollama
    networks:
      - smartrecruit-net
    restart: unless-stopped

  mongodb:
    image: mongo:7
    container_name: mongodb
    restart: unless-stopped
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_USER:-admin}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_PASSWORD:-changeme123!}
      - MONGO_INITDB_DATABASE=${MONGO_DB:-smartrecruit}
    volumes:
      - mongodb_data:/data/db
      - mongodb_config:/data/configdb
      - ./mongodb/init-scripts:/docker-entrypoint-initdb.d:ro
    networks:
      - smartrecruit-net
    command: ["mongod", "--auth"]

  front-end:
    build:
      context: ./front-end
      dockerfile: Dockerfile
    image: front-end
    container_name: front-end
    ports:
      - "5100:3000"
    environment:
      - NODE_ENV=production
      - MONGODB_URI=mongodb://${MONGO_USER:-admin}:${MONGO_PASSWORD:-changeme123!}@mongodb:27017/${MONGO_DB:-smartrecruit}?authSource=admin
      - MONGODB_DB=${MONGO_DB:-smartrecruit}
    depends_on:
      - mongodb
    networks:
      - smartrecruit-net
    restart: always

# ===========================================
# Volumes
# ===========================================
volumes:
  ollama_data:
    driver: local
  ollama_webui_data:
    driver: local
  n8n_data:
    driver: local
  pgadmin_data:
    driver: local
  mongodb_data:
    driver: local
  mongodb_config:
    driver: local

# ===========================================
# Networks
# ===========================================
networks:
  smartrecruit-net:
    driver: bridge
